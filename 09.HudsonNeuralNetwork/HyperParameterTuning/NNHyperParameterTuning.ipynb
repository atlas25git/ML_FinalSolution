{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNHyperParameterTuning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uz_oYSOf5dQQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k10tR8t7N8Gi"
      },
      "source": [
        "# Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqtrIORSN8Gi"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Onw48ksZN8Gi"
      },
      "source": [
        "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
        "    for layer in range(n_hidden):\n",
        "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
        "    model.add(keras.layers.Dense(1))\n",
        "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
        "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK-ZxcKEN8Gi"
      },
      "source": [
        "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reDem4NPN8Gi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ef2a9d0-d204-421d-ac4e-0c5b3b745e67"
      },
      "source": [
        "keras_reg.fit(X_train, y_train, epochs=100,\n",
        "              validation_data=(X_valid, y_valid),\n",
        "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 1.5673 - val_loss: 20.7721\n",
            "Epoch 2/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 1.3216 - val_loss: 5.0266\n",
            "Epoch 3/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5972 - val_loss: 0.5490\n",
            "Epoch 4/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4985 - val_loss: 0.4529\n",
            "Epoch 5/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4608 - val_loss: 0.4188\n",
            "Epoch 6/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4410 - val_loss: 0.4129\n",
            "Epoch 7/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4463 - val_loss: 0.4004\n",
            "Epoch 8/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4283 - val_loss: 0.3944\n",
            "Epoch 9/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4139 - val_loss: 0.3961\n",
            "Epoch 10/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4107 - val_loss: 0.4071\n",
            "Epoch 11/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3992 - val_loss: 0.3855\n",
            "Epoch 12/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3982 - val_loss: 0.4136\n",
            "Epoch 13/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3983 - val_loss: 0.3997\n",
            "Epoch 14/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3910 - val_loss: 0.3818\n",
            "Epoch 15/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3948 - val_loss: 0.3829\n",
            "Epoch 16/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3981 - val_loss: 0.3739\n",
            "Epoch 17/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3821 - val_loss: 0.4022\n",
            "Epoch 18/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3851 - val_loss: 0.3873\n",
            "Epoch 19/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3753 - val_loss: 0.3768\n",
            "Epoch 20/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3634 - val_loss: 0.4191\n",
            "Epoch 21/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3787 - val_loss: 0.3927\n",
            "Epoch 22/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3628 - val_loss: 0.4237\n",
            "Epoch 23/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3892 - val_loss: 0.3523\n",
            "Epoch 24/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3676 - val_loss: 0.3842\n",
            "Epoch 25/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3677 - val_loss: 0.4162\n",
            "Epoch 26/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3690 - val_loss: 0.3980\n",
            "Epoch 27/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3731 - val_loss: 0.3474\n",
            "Epoch 28/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3725 - val_loss: 0.3920\n",
            "Epoch 29/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3660 - val_loss: 0.3566\n",
            "Epoch 30/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3700 - val_loss: 0.4191\n",
            "Epoch 31/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3635 - val_loss: 0.3721\n",
            "Epoch 32/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3628 - val_loss: 0.3948\n",
            "Epoch 33/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3647 - val_loss: 0.3423\n",
            "Epoch 34/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3547 - val_loss: 0.3453\n",
            "Epoch 35/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3496 - val_loss: 0.4068\n",
            "Epoch 36/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3476 - val_loss: 0.3417\n",
            "Epoch 37/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3786 - val_loss: 0.3787\n",
            "Epoch 38/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3540 - val_loss: 0.3379\n",
            "Epoch 39/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3769 - val_loss: 0.3419\n",
            "Epoch 40/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3522 - val_loss: 0.3705\n",
            "Epoch 41/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3705 - val_loss: 0.3659\n",
            "Epoch 42/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3545 - val_loss: 0.3803\n",
            "Epoch 43/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3597 - val_loss: 0.3765\n",
            "Epoch 44/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3443 - val_loss: 0.3813\n",
            "Epoch 45/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3591 - val_loss: 0.3326\n",
            "Epoch 46/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3528 - val_loss: 0.3385\n",
            "Epoch 47/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3663 - val_loss: 0.3655\n",
            "Epoch 48/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3479 - val_loss: 0.3579\n",
            "Epoch 49/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3601 - val_loss: 0.3360\n",
            "Epoch 50/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3616 - val_loss: 0.3317\n",
            "Epoch 51/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3532 - val_loss: 0.3562\n",
            "Epoch 52/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3427 - val_loss: 0.3521\n",
            "Epoch 53/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3503 - val_loss: 0.4579\n",
            "Epoch 54/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3402 - val_loss: 0.3809\n",
            "Epoch 55/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3496 - val_loss: 0.3540\n",
            "Epoch 56/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3401 - val_loss: 0.3725\n",
            "Epoch 57/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3440 - val_loss: 0.3337\n",
            "Epoch 58/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3347 - val_loss: 0.4011\n",
            "Epoch 59/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3445 - val_loss: 0.3263\n",
            "Epoch 60/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3414 - val_loss: 0.3271\n",
            "Epoch 61/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3623 - val_loss: 0.3349\n",
            "Epoch 62/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3497 - val_loss: 0.3541\n",
            "Epoch 63/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3485 - val_loss: 0.3428\n",
            "Epoch 64/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3300 - val_loss: 0.3280\n",
            "Epoch 65/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3410 - val_loss: 0.3292\n",
            "Epoch 66/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3364 - val_loss: 0.3301\n",
            "Epoch 67/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3559 - val_loss: 0.3254\n",
            "Epoch 68/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3372 - val_loss: 0.3245\n",
            "Epoch 69/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3394 - val_loss: 0.3255\n",
            "Epoch 70/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3350 - val_loss: 0.3666\n",
            "Epoch 71/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3428 - val_loss: 0.3370\n",
            "Epoch 72/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3261 - val_loss: 0.3267\n",
            "Epoch 73/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3409 - val_loss: 0.3245\n",
            "Epoch 74/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3394 - val_loss: 0.3663\n",
            "Epoch 75/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3286 - val_loss: 0.3290\n",
            "Epoch 76/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3391 - val_loss: 0.3235\n",
            "Epoch 77/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3293 - val_loss: 0.3386\n",
            "Epoch 78/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3372 - val_loss: 0.3362\n",
            "Epoch 79/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3366 - val_loss: 0.3222\n",
            "Epoch 80/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3375 - val_loss: 0.3644\n",
            "Epoch 81/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3381 - val_loss: 0.3420\n",
            "Epoch 82/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3481 - val_loss: 0.3253\n",
            "Epoch 83/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3443 - val_loss: 0.3246\n",
            "Epoch 84/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3237 - val_loss: 0.3953\n",
            "Epoch 85/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3305 - val_loss: 0.3415\n",
            "Epoch 86/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3268 - val_loss: 0.3190\n",
            "Epoch 87/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3481 - val_loss: 0.3277\n",
            "Epoch 88/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3299 - val_loss: 0.3295\n",
            "Epoch 89/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3285 - val_loss: 0.3247\n",
            "Epoch 90/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3239 - val_loss: 0.3281\n",
            "Epoch 91/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3290 - val_loss: 0.3201\n",
            "Epoch 92/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3342 - val_loss: 0.3393\n",
            "Epoch 93/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3487 - val_loss: 0.3170\n",
            "Epoch 94/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3258 - val_loss: 0.3526\n",
            "Epoch 95/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3275 - val_loss: 0.4813\n",
            "Epoch 96/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3416 - val_loss: 0.3465\n",
            "Epoch 97/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3247 - val_loss: 0.4632\n",
            "Epoch 98/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3271 - val_loss: 0.6725\n",
            "Epoch 99/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3193 - val_loss: 0.5924\n",
            "Epoch 100/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3442 - val_loss: 0.5271\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb06ed90ed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyM8reV8N8Gj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e562548-4090-40b4-b4e4-a0707cf26e00"
      },
      "source": [
        "mse_test = keras_reg.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "162/162 [==============================] - 0s 816us/step - loss: 0.3346\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnfySR6XN8Gj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e68cf5e-746d-40b2-835e-e0500001f162"
      },
      "source": [
        "y_pred = keras_reg.predict(X_new)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:8 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb075a28560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpaDH3nwN8Gj"
      },
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZL1oT2VN8Gj"
      },
      "source": [
        "**Warning**: the following cell crashes at the end of training. This seems to be caused by [Keras issue #13586](https://github.com/keras-team/keras/issues/13586), which was triggered by a recent change in Scikit-Learn. [Pull Request #13598](https://github.com/keras-team/keras/pull/13598) seems to fix the issue, so this problem should be resolved soon. In the meantime, I've added `.tolist()` and `.rvs(1000).tolist()` as workarounds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ts6hgDiPN8Gj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbcd58b1-f530-4bed-b21e-6b1a9dc2f86b"
      },
      "source": [
        "from scipy.stats import reciprocal\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_distribs = {\n",
        "    \"n_hidden\": [0, 1, 2, 3],\n",
        "    \"n_neurons\": np.arange(1, 100)               .tolist(),\n",
        "    \"learning_rate\": reciprocal(3e-4, 3e-2)      .rvs(1000).tolist(),\n",
        "}\n",
        "\n",
        "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
        "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
        "                  validation_data=(X_valid, y_valid),\n",
        "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "[CV] n_neurons=4, n_hidden=1, learning_rate=0.022174573948353458 .....\n",
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "242/242 [==============================] - 1s 2ms/step - loss: 1.3827 - val_loss: 0.4703\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4880 - val_loss: 0.4247\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4541 - val_loss: 0.4052\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4518 - val_loss: 0.3975\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4337 - val_loss: 0.3991\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4263 - val_loss: 0.4031\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4385 - val_loss: 0.4043\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4301 - val_loss: 0.3929\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4108 - val_loss: 0.4040\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4200 - val_loss: 0.3886\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4099 - val_loss: 0.3999\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3897 - val_loss: 0.4085\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4265 - val_loss: 0.3922\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4108 - val_loss: 0.3918\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4070 - val_loss: 0.3886\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4032 - val_loss: 0.3933\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4212 - val_loss: 0.3907\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4241 - val_loss: 0.3955\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4040 - val_loss: 0.3935\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4146 - val_loss: 0.3891\n",
            "121/121 [==============================] - 0s 901us/step - loss: 0.4251\n",
            "[CV]  n_neurons=4, n_hidden=1, learning_rate=0.022174573948353458, total=   8.3s\n",
            "[CV] n_neurons=4, n_hidden=1, learning_rate=0.022174573948353458 .....\n",
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "242/242 [==============================] - 1s 2ms/step - loss: 1.3852 - val_loss: 0.4860\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4722 - val_loss: 0.4280\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4384 - val_loss: 0.5791\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4422 - val_loss: 0.4549\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4527 - val_loss: 0.5250\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4474 - val_loss: 0.5486\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4246 - val_loss: 0.5871\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4382 - val_loss: 0.4759\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4299 - val_loss: 0.7523\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4390 - val_loss: 0.7478\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4395 - val_loss: 0.8981\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4234 - val_loss: 0.8543\n",
            "121/121 [==============================] - 0s 791us/step - loss: 0.4537\n",
            "[CV]  n_neurons=4, n_hidden=1, learning_rate=0.022174573948353458, total=   5.1s\n",
            "[CV] n_neurons=4, n_hidden=1, learning_rate=0.022174573948353458 .....\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 13.5523 - val_loss: 4.2468\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.2460 - val_loss: 0.5794\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5520 - val_loss: 0.4357\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4507 - val_loss: 0.4169\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4365 - val_loss: 0.4135\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4283 - val_loss: 0.4206\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4420 - val_loss: 0.4100\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4636 - val_loss: 0.4155\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4411 - val_loss: 0.4111\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4840 - val_loss: 0.4076\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4626 - val_loss: 0.4062\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4326 - val_loss: 0.4078\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4226 - val_loss: 0.4160\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4260 - val_loss: 0.4158\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4551 - val_loss: 0.4137\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4552 - val_loss: 0.4069\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4343 - val_loss: 0.4119\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4453 - val_loss: 0.4149\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4530 - val_loss: 0.4081\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 1ms/step - loss: 0.4502 - val_loss: 0.4141\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4420 - val_loss: 0.4100\n",
            "121/121 [==============================] - 0s 900us/step - loss: 0.4473\n",
            "[CV]  n_neurons=4, n_hidden=1, learning_rate=0.022174573948353458, total=   8.7s\n",
            "[CV] n_neurons=94, n_hidden=2, learning_rate=0.005432590230265343 ....\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.7737 - val_loss: 6.2480\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5899 - val_loss: 5.2166\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5147 - val_loss: 0.4474\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4477 - val_loss: 0.3901\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3980 - val_loss: 0.3736\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3757 - val_loss: 0.3803\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3701 - val_loss: 0.3813\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3632 - val_loss: 0.3961\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3512 - val_loss: 0.3988\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3532 - val_loss: 0.3891\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3358 - val_loss: 0.3870\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3252 - val_loss: 0.3770\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3499 - val_loss: 0.3770\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3382 - val_loss: 0.3843\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3331 - val_loss: 0.3770\n",
            "121/121 [==============================] - 0s 991us/step - loss: 0.3561\n",
            "[CV]  n_neurons=94, n_hidden=2, learning_rate=0.005432590230265343, total=   7.2s\n",
            "[CV] n_neurons=94, n_hidden=2, learning_rate=0.005432590230265343 ....\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.5396 - val_loss: 3.5738\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5129 - val_loss: 0.7767\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4283 - val_loss: 0.5515\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4097 - val_loss: 0.5335\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3926 - val_loss: 0.5336\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3760 - val_loss: 0.6750\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3580 - val_loss: 0.8462\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3622 - val_loss: 0.8724\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3518 - val_loss: 0.9645\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3560 - val_loss: 0.7225\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3517 - val_loss: 0.7257\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3367 - val_loss: 0.7216\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3334 - val_loss: 0.8440\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3244 - val_loss: 0.7065\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3650\n",
            "[CV]  n_neurons=94, n_hidden=2, learning_rate=0.005432590230265343, total=   6.7s\n",
            "[CV] n_neurons=94, n_hidden=2, learning_rate=0.005432590230265343 ....\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.7832 - val_loss: 2.9433\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5594 - val_loss: 4.2557\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4797 - val_loss: 2.8526\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4774 - val_loss: 1.6798\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3983 - val_loss: 0.4322\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3736 - val_loss: 0.4172\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3719 - val_loss: 0.3769\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3883 - val_loss: 0.3688\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3652 - val_loss: 0.4032\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3587 - val_loss: 0.3418\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3769 - val_loss: 0.4452\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3487 - val_loss: 0.3453\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3259 - val_loss: 0.3395\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3368 - val_loss: 0.4355\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3603 - val_loss: 0.3388\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3422 - val_loss: 0.4037\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3297 - val_loss: 0.3302\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3386 - val_loss: 0.3582\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3523 - val_loss: 0.3543\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3401 - val_loss: 0.3465\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3327 - val_loss: 0.3247\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3455 - val_loss: 0.3260\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3303 - val_loss: 0.3443\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3216 - val_loss: 0.3386\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3195 - val_loss: 0.3660\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3209 - val_loss: 0.3921\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3392 - val_loss: 0.3140\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3303 - val_loss: 0.3192\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3268 - val_loss: 0.4183\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3202 - val_loss: 0.3196\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3092 - val_loss: 0.3155\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3291 - val_loss: 0.4207\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3191 - val_loss: 0.3133\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3036 - val_loss: 0.4116\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3126 - val_loss: 0.4760\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3006 - val_loss: 0.8684\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3119 - val_loss: 0.6797\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3353 - val_loss: 1.0120\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3220 - val_loss: 0.4274\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3120 - val_loss: 1.3597\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3396 - val_loss: 0.5999\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3033 - val_loss: 1.8763\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3197 - val_loss: 1.7086\n",
            "121/121 [==============================] - 0s 950us/step - loss: 0.3210\n",
            "[CV]  n_neurons=94, n_hidden=2, learning_rate=0.005432590230265343, total=  19.8s\n",
            "[CV] n_neurons=51, n_hidden=1, learning_rate=0.00037078874137762145 ..\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 5.2328 - val_loss: 13.3699\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 2.4156 - val_loss: 10.8972\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.4953 - val_loss: 7.7330\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.1092 - val_loss: 5.0744\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.8935 - val_loss: 3.2363\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.8194 - val_loss: 2.1597\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7802 - val_loss: 1.4840\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7285 - val_loss: 1.1083\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6921 - val_loss: 0.8942\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6951 - val_loss: 0.7687\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6599 - val_loss: 0.6947\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6237 - val_loss: 0.6524\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6619 - val_loss: 0.6234\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6487 - val_loss: 0.6061\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6429 - val_loss: 0.5933\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6103 - val_loss: 0.5819\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6492 - val_loss: 0.5733\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6227 - val_loss: 0.5650\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6024 - val_loss: 0.5578\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5992 - val_loss: 0.5508\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5874 - val_loss: 0.5446\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5653 - val_loss: 0.5384\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5863 - val_loss: 0.5326\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5639 - val_loss: 0.5266\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5689 - val_loss: 0.5214\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5438 - val_loss: 0.5166\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5653 - val_loss: 0.5116\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5540 - val_loss: 0.5076\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5635 - val_loss: 0.5035\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5438 - val_loss: 0.4989\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5203 - val_loss: 0.4946\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 0.4915\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5159 - val_loss: 0.4883\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5200 - val_loss: 0.4856\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5080 - val_loss: 0.4828\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4939 - val_loss: 0.4789\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5136 - val_loss: 0.4780\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4794 - val_loss: 0.4742\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5037 - val_loss: 0.4729\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4797 - val_loss: 0.4714\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4870 - val_loss: 0.4686\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5008 - val_loss: 0.4666\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4892 - val_loss: 0.4646\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4786 - val_loss: 0.4636\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4812 - val_loss: 0.4616\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4710 - val_loss: 0.4582\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4787 - val_loss: 0.4581\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4574 - val_loss: 0.4573\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4752 - val_loss: 0.4560\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4641 - val_loss: 0.4544\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4536 - val_loss: 0.4525\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4800 - val_loss: 0.4527\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4622 - val_loss: 0.4522\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4648 - val_loss: 0.4509\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4387 - val_loss: 0.4509\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4897 - val_loss: 0.4513\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4494 - val_loss: 0.4496\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4645 - val_loss: 0.4510\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4580 - val_loss: 0.4502\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4393 - val_loss: 0.4478\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4271 - val_loss: 0.4485\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4362 - val_loss: 0.4488\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4499 - val_loss: 0.4477\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4377 - val_loss: 0.4497\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4153 - val_loss: 0.4512\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4718 - val_loss: 0.4484\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4375 - val_loss: 0.4483\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4390 - val_loss: 0.4494\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4460 - val_loss: 0.4492\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4546 - val_loss: 0.4476\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4346 - val_loss: 0.4481\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4486 - val_loss: 0.4503\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4463 - val_loss: 0.4486\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4312 - val_loss: 0.4491\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4328 - val_loss: 0.4496\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4235 - val_loss: 0.4483\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4181 - val_loss: 0.4474\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4187 - val_loss: 0.4490\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4158 - val_loss: 0.4495\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4270 - val_loss: 0.4468\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3977 - val_loss: 0.4492\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4071 - val_loss: 0.4525\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3911 - val_loss: 0.4504\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4320 - val_loss: 0.4525\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4206 - val_loss: 0.4495\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3961 - val_loss: 0.4548\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4143 - val_loss: 0.4512\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4150 - val_loss: 0.4481\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4045 - val_loss: 0.4472\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3976 - val_loss: 0.4506\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.4209\n",
            "[CV]  n_neurons=51, n_hidden=1, learning_rate=0.00037078874137762145, total=  38.3s\n",
            "[CV] n_neurons=51, n_hidden=1, learning_rate=0.00037078874137762145 ..\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 4.4546 - val_loss: 7.5238\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.7950 - val_loss: 8.6120\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.1115 - val_loss: 8.4896\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.9287 - val_loss: 7.7423\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.8253 - val_loss: 6.8202\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7837 - val_loss: 5.9344\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7711 - val_loss: 5.1492\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7292 - val_loss: 4.4548\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7279 - val_loss: 3.9122\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7055 - val_loss: 3.4233\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6956 - val_loss: 2.9997\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6640 - val_loss: 2.6082\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6539 - val_loss: 2.2766\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6447 - val_loss: 1.9984\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6831 - val_loss: 1.7447\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6364 - val_loss: 1.5300\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6425 - val_loss: 1.3410\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6340 - val_loss: 1.1762\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6140 - val_loss: 1.0345\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6101 - val_loss: 0.9174\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5938 - val_loss: 0.8153\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5975 - val_loss: 0.7363\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5957 - val_loss: 0.6696\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5714 - val_loss: 0.6187\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5535 - val_loss: 0.5778\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5553 - val_loss: 0.5491\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5725 - val_loss: 0.5299\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5688 - val_loss: 0.5199\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5619 - val_loss: 0.5172\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5510 - val_loss: 0.5206\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5401 - val_loss: 0.5312\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.5370 - val_loss: 0.5447\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5423 - val_loss: 0.5639\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5211 - val_loss: 0.5821\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5081 - val_loss: 0.6039\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5036 - val_loss: 0.6306\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5191 - val_loss: 0.6564\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4928 - val_loss: 0.6820\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5096 - val_loss: 0.7087\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.5160\n",
            "[CV]  n_neurons=51, n_hidden=1, learning_rate=0.00037078874137762145, total=  17.8s\n",
            "[CV] n_neurons=51, n_hidden=1, learning_rate=0.00037078874137762145 ..\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 4.8993 - val_loss: 7.4460\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 2.4173 - val_loss: 5.2071\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.4701 - val_loss: 2.9554\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.1716 - val_loss: 1.7752\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.9242 - val_loss: 1.1201\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.8307 - val_loss: 0.8519\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7780 - val_loss: 0.7512\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7632 - val_loss: 0.7064\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7361 - val_loss: 0.6896\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6859 - val_loss: 0.6760\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7064 - val_loss: 0.6687\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6826 - val_loss: 0.6577\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6416 - val_loss: 0.6454\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6539 - val_loss: 0.6355\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6736 - val_loss: 0.6256\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6529 - val_loss: 0.6213\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6253 - val_loss: 0.6120\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6484 - val_loss: 0.6024\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6228 - val_loss: 0.5998\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6079 - val_loss: 0.5901\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5912 - val_loss: 0.5822\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6250 - val_loss: 0.5763\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5804 - val_loss: 0.5664\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5735 - val_loss: 0.5574\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5793 - val_loss: 0.5527\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5576 - val_loss: 0.5452\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5786 - val_loss: 0.5437\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5683 - val_loss: 0.5366\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5475 - val_loss: 0.5322\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5471 - val_loss: 0.5264\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5281 - val_loss: 0.5234\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5547 - val_loss: 0.5175\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5437 - val_loss: 0.5137\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5113 - val_loss: 0.5078\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5125 - val_loss: 0.5045\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5127 - val_loss: 0.4970\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5158 - val_loss: 0.4911\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5132 - val_loss: 0.4887\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5140 - val_loss: 0.4847\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4995 - val_loss: 0.4815\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4795 - val_loss: 0.4776\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4838 - val_loss: 0.4736\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4966 - val_loss: 0.4706\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4932 - val_loss: 0.4673\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4810 - val_loss: 0.4655\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4737 - val_loss: 0.4625\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4866 - val_loss: 0.4576\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4719 - val_loss: 0.4554\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4859 - val_loss: 0.4525\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4618 - val_loss: 0.4495\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4862 - val_loss: 0.4468\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4576 - val_loss: 0.4446\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4641 - val_loss: 0.4420\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4641 - val_loss: 0.4394\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4560 - val_loss: 0.4373\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4620 - val_loss: 0.4349\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4542 - val_loss: 0.4330\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4659 - val_loss: 0.4311\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4584 - val_loss: 0.4291\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4684 - val_loss: 0.4277\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4678 - val_loss: 0.4257\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4516 - val_loss: 0.4241\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4410 - val_loss: 0.4224\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4622 - val_loss: 0.4208\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4594 - val_loss: 0.4193\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4354 - val_loss: 0.4180\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4460 - val_loss: 0.4164\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4504 - val_loss: 0.4151\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4247 - val_loss: 0.4141\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4433 - val_loss: 0.4124\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4618 - val_loss: 0.4112\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4168 - val_loss: 0.4101\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4359 - val_loss: 0.4088\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4307 - val_loss: 0.4081\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4273 - val_loss: 0.4073\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4386 - val_loss: 0.4070\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4324 - val_loss: 0.4056\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4313 - val_loss: 0.4040\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4328 - val_loss: 0.4034\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4146 - val_loss: 0.4033\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4138 - val_loss: 0.4019\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4241 - val_loss: 0.4008\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4112 - val_loss: 0.4002\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4320 - val_loss: 0.3996\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4259 - val_loss: 0.3983\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4110 - val_loss: 0.3980\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4237 - val_loss: 0.3981\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4058 - val_loss: 0.3969\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4303 - val_loss: 0.3978\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4157 - val_loss: 0.3961\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4229 - val_loss: 0.3951\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4118 - val_loss: 0.3938\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4005 - val_loss: 0.3938\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4222 - val_loss: 0.3935\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4279 - val_loss: 0.3934\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4027 - val_loss: 0.3932\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4108 - val_loss: 0.3939\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3998 - val_loss: 0.3913\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4002 - val_loss: 0.3916\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4052 - val_loss: 0.3918\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.4139\n",
            "[CV]  n_neurons=51, n_hidden=1, learning_rate=0.00037078874137762145, total=  43.1s\n",
            "[CV] n_neurons=70, n_hidden=2, learning_rate=0.0016535051383872363 ...\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 3.4453 - val_loss: 1.3536\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.7645 - val_loss: 0.7463\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6590 - val_loss: 0.5899\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6064 - val_loss: 0.5366\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5580 - val_loss: 0.5063\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5150 - val_loss: 0.4813\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4985 - val_loss: 0.4639\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4716 - val_loss: 0.4427\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4477 - val_loss: 0.4393\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4411 - val_loss: 0.4137\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4204 - val_loss: 0.4071\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3978 - val_loss: 0.3983\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4290 - val_loss: 0.3933\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4111 - val_loss: 0.3972\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4041 - val_loss: 0.3852\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3923 - val_loss: 0.3830\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4072 - val_loss: 0.3947\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4075 - val_loss: 0.3713\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.3752\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3867 - val_loss: 0.3741\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3800 - val_loss: 0.3782\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3686 - val_loss: 0.3637\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3795 - val_loss: 0.3723\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3691 - val_loss: 0.3707\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3751 - val_loss: 0.4047\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3599 - val_loss: 0.3839\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3795 - val_loss: 0.4167\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3664 - val_loss: 0.3500\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3666 - val_loss: 0.3792\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3629 - val_loss: 0.3636\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3586 - val_loss: 0.3476\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3489 - val_loss: 0.3566\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3517 - val_loss: 0.3611\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3521 - val_loss: 0.3414\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3499 - val_loss: 0.3473\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3469 - val_loss: 0.3946\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3453 - val_loss: 0.4404\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3539 - val_loss: 0.4725\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3449 - val_loss: 0.3723\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3307 - val_loss: 0.4019\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3408 - val_loss: 0.3376\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3456 - val_loss: 0.3377\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3436 - val_loss: 0.3354\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3430 - val_loss: 0.3734\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3496 - val_loss: 0.3336\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3306 - val_loss: 0.3562\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3370 - val_loss: 0.3546\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3262 - val_loss: 0.3399\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3510 - val_loss: 0.3304\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3347 - val_loss: 0.3851\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3238 - val_loss: 0.3430\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3495 - val_loss: 0.3363\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3329 - val_loss: 0.3386\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3366 - val_loss: 0.3294\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3260 - val_loss: 0.3654\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3558 - val_loss: 0.3310\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3366 - val_loss: 0.3729\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3374 - val_loss: 0.3375\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3415 - val_loss: 0.3263\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3332 - val_loss: 0.3402\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3199 - val_loss: 0.3439\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3275 - val_loss: 0.3584\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3341 - val_loss: 0.3303\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3222 - val_loss: 0.3682\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3119 - val_loss: 0.3293\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3518 - val_loss: 0.3276\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3314 - val_loss: 0.3558\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3287 - val_loss: 0.3296\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3316 - val_loss: 0.3437\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3550\n",
            "[CV]  n_neurons=70, n_hidden=2, learning_rate=0.0016535051383872363, total=  32.9s\n",
            "[CV] n_neurons=70, n_hidden=2, learning_rate=0.0016535051383872363 ...\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 3.2276 - val_loss: 3.4090\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7673 - val_loss: 1.6754\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6369 - val_loss: 0.9319\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6031 - val_loss: 0.6042\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5652 - val_loss: 0.5061\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5258 - val_loss: 0.5058\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4977 - val_loss: 0.5272\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4759 - val_loss: 0.5600\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4640 - val_loss: 0.5367\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4464 - val_loss: 0.5220\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4347 - val_loss: 0.4878\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4163 - val_loss: 0.4531\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4113 - val_loss: 0.4182\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3961 - val_loss: 0.3877\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4222 - val_loss: 0.3818\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3975 - val_loss: 0.4023\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3999 - val_loss: 0.4348\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4069 - val_loss: 0.4934\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3895 - val_loss: 0.5340\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3872 - val_loss: 0.5981\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.6540\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3803 - val_loss: 0.7244\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3840 - val_loss: 0.8044\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3677 - val_loss: 0.8586\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3480 - val_loss: 0.9090\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3884\n",
            "[CV]  n_neurons=70, n_hidden=2, learning_rate=0.0016535051383872363, total=  12.6s\n",
            "[CV] n_neurons=70, n_hidden=2, learning_rate=0.0016535051383872363 ...\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 3.3058 - val_loss: 2.1643\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7651 - val_loss: 0.6141\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6136 - val_loss: 0.5601\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5596 - val_loss: 0.5241\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5239 - val_loss: 0.5017\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4854 - val_loss: 0.4749\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4781 - val_loss: 0.4558\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4755 - val_loss: 0.4297\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4463 - val_loss: 0.4464\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4310 - val_loss: 0.4189\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4329 - val_loss: 0.4438\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4131 - val_loss: 0.4250\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3859 - val_loss: 0.4009\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3923 - val_loss: 0.4403\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4130 - val_loss: 0.4014\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3992 - val_loss: 0.4247\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3806 - val_loss: 0.3964\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3962 - val_loss: 0.3974\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3999 - val_loss: 0.4229\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3901 - val_loss: 0.4053\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3989\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3974 - val_loss: 0.3957\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3763 - val_loss: 0.3864\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3718 - val_loss: 0.4022\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3711 - val_loss: 0.3729\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3712 - val_loss: 0.3645\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3836 - val_loss: 0.4107\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3786 - val_loss: 0.3925\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3648 - val_loss: 0.4265\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3695 - val_loss: 0.3879\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3592 - val_loss: 0.3789\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3819 - val_loss: 0.4080\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3659 - val_loss: 0.3873\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3501 - val_loss: 0.4232\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3550 - val_loss: 0.3718\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3490 - val_loss: 0.3663\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3555\n",
            "[CV]  n_neurons=70, n_hidden=2, learning_rate=0.0016535051383872363, total=  18.4s\n",
            "[CV] n_neurons=40, n_hidden=0, learning_rate=0.01824796188192035 .....\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.9995 - val_loss: 297.3654\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.2481 - val_loss: 539.0367\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 2.5441 - val_loss: 3736.4524\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 7.4651 - val_loss: 12227.7012\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 22.4715 - val_loss: 61529.1094\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 2537.2826 - val_loss: 268363.5938\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 2132.8549 - val_loss: 1210517.8750\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 32696.8532 - val_loss: 5411007.0000\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 28036.3370 - val_loss: 24506728.0000\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 910067.5168 - val_loss: 119813168.0000\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1721900.0868 - val_loss: 529731552.0000\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 1402366.7500\n",
            "[CV]  n_neurons=40, n_hidden=0, learning_rate=0.01824796188192035, total=   5.2s\n",
            "[CV] n_neurons=40, n_hidden=0, learning_rate=0.01824796188192035 .....\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.2323 - val_loss: 15.8284\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5228 - val_loss: 22.4892\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5292 - val_loss: 24.7894\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5081 - val_loss: 22.4864\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5095 - val_loss: 21.9009\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5093 - val_loss: 21.2895\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4936 - val_loss: 19.9064\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5221 - val_loss: 22.5013\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5027 - val_loss: 20.0987\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4831 - val_loss: 10.7128\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5128 - val_loss: 19.7319\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4957 - val_loss: 24.3237\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5081 - val_loss: 25.9485\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4740 - val_loss: 10.5277\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5379 - val_loss: 17.1916\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5078 - val_loss: 21.8347\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4993 - val_loss: 11.7743\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5211 - val_loss: 14.1555\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5103 - val_loss: 20.9814\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4812 - val_loss: 12.3621\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5134 - val_loss: 25.9146\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4890 - val_loss: 16.0461\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5148 - val_loss: 19.4877\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4909 - val_loss: 12.1054\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.7813\n",
            "[CV]  n_neurons=40, n_hidden=0, learning_rate=0.01824796188192035, total=  10.8s\n",
            "[CV] n_neurons=40, n_hidden=0, learning_rate=0.01824796188192035 .....\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.9669 - val_loss: 307.7496\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.0908 - val_loss: 76.3015\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.8437 - val_loss: 795.2291\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 41.8219 - val_loss: 704.0449\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.0379 - val_loss: 2668.0283\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 6.1716 - val_loss: 1446.2606\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 3.3018 - val_loss: 1540.5367\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 71.5700 - val_loss: 1396.7107\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 6.0212 - val_loss: 1334.0837\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 2.0299 - val_loss: 216.7264\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 21.3465 - val_loss: 125.2064\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7510 - val_loss: 2.2902\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4922 - val_loss: 790.5422\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 5.4409 - val_loss: 468.7426\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 1.0499 - val_loss: 1073.9150\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 45.2524 - val_loss: 865.6382\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 2.7759 - val_loss: 1128.1503\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 2.7236 - val_loss: 499.5191\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 34.6839 - val_loss: 309.7941\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 2.3475 - val_loss: 354.6340\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 2.4646 - val_loss: 559.4488\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 3.0812 - val_loss: 393.8695\n",
            "121/121 [==============================] - 0s 998us/step - loss: 0.6226\n",
            "[CV]  n_neurons=40, n_hidden=0, learning_rate=0.01824796188192035, total=  10.0s\n",
            "[CV] n_neurons=30, n_hidden=3, learning_rate=0.0045455096956331 ......\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.9862 - val_loss: 1.4543\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6404 - val_loss: 0.9557\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5532 - val_loss: 0.4628\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4956 - val_loss: 0.4214\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4377 - val_loss: 0.3984\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4032 - val_loss: 0.4056\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4015 - val_loss: 0.3741\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3915 - val_loss: 0.3926\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3725 - val_loss: 0.3832\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3731 - val_loss: 0.3929\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3537 - val_loss: 0.3570\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3410 - val_loss: 0.3790\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3720 - val_loss: 0.3840\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3560 - val_loss: 0.3950\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3490 - val_loss: 0.3751\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3482 - val_loss: 0.3955\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3559 - val_loss: 0.3900\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3621 - val_loss: 0.3902\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3365 - val_loss: 0.3942\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3438 - val_loss: 0.3811\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3389 - val_loss: 0.3907\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3624\n",
            "[CV]  n_neurons=30, n_hidden=3, learning_rate=0.0045455096956331, total=  10.9s\n",
            "[CV] n_neurons=30, n_hidden=3, learning_rate=0.0045455096956331 ......\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 1.7235 - val_loss: 0.5822\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5852 - val_loss: 0.4873\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4784 - val_loss: 0.4420\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4436 - val_loss: 0.4139\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4223 - val_loss: 0.4132\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3955 - val_loss: 0.4464\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3768 - val_loss: 0.4717\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3800 - val_loss: 0.5331\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3620 - val_loss: 0.6951\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3645 - val_loss: 0.6944\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3646 - val_loss: 0.8506\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3432 - val_loss: 0.7660\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3419 - val_loss: 0.8731\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3305 - val_loss: 0.9306\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3605 - val_loss: 0.9345\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3685\n",
            "[CV]  n_neurons=30, n_hidden=3, learning_rate=0.0045455096956331, total=   8.0s\n",
            "[CV] n_neurons=30, n_hidden=3, learning_rate=0.0045455096956331 ......\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.7434 - val_loss: 0.6796\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5868 - val_loss: 0.4957\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5017 - val_loss: 0.4633\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4473 - val_loss: 0.4565\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4218 - val_loss: 0.4150\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3928 - val_loss: 0.4331\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3924 - val_loss: 0.3887\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4047 - val_loss: 0.3785\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3805 - val_loss: 0.4233\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3749 - val_loss: 0.3652\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3866 - val_loss: 0.4336\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3635 - val_loss: 0.3763\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3414 - val_loss: 0.3632\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3498 - val_loss: 0.4460\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3760 - val_loss: 0.3555\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3554 - val_loss: 0.3947\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3443 - val_loss: 0.3623\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3532 - val_loss: 0.3774\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3664 - val_loss: 0.3806\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3544 - val_loss: 0.3420\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3428 - val_loss: 0.3452\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3599 - val_loss: 0.3273\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3386 - val_loss: 0.3279\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3312 - val_loss: 0.4328\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3306 - val_loss: 0.3426\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3298 - val_loss: 0.3228\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3435 - val_loss: 0.4407\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3403 - val_loss: 0.3301\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3288 - val_loss: 0.4053\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3297 - val_loss: 0.3360\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3188 - val_loss: 0.3330\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3392 - val_loss: 0.3658\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3285 - val_loss: 0.3479\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3120 - val_loss: 0.3596\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3144 - val_loss: 0.3131\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3094 - val_loss: 0.3617\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3215 - val_loss: 0.3386\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3191 - val_loss: 0.5222\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3300 - val_loss: 0.3333\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3192 - val_loss: 0.4050\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3023 - val_loss: 0.3326\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3030 - val_loss: 0.3593\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3221 - val_loss: 0.3245\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3249 - val_loss: 0.3830\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3108 - val_loss: 0.3084\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3079 - val_loss: 0.3726\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3089 - val_loss: 0.3160\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3054 - val_loss: 0.3005\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3112 - val_loss: 0.4075\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3104 - val_loss: 0.2996\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3180 - val_loss: 0.4364\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3030 - val_loss: 0.3002\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3062 - val_loss: 0.2985\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3021 - val_loss: 0.2960\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3003 - val_loss: 0.2948\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3071 - val_loss: 0.3314\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3001 - val_loss: 0.3077\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3082 - val_loss: 0.2979\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3090 - val_loss: 0.3541\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3084 - val_loss: 0.3919\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3144 - val_loss: 0.3128\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3002 - val_loss: 0.3066\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3010 - val_loss: 0.2950\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3148 - val_loss: 0.3041\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2976 - val_loss: 0.2944\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2886 - val_loss: 0.3637\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2994 - val_loss: 0.3032\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3084 - val_loss: 0.3324\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2923 - val_loss: 0.2901\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2912 - val_loss: 0.3183\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3069 - val_loss: 0.2875\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2800 - val_loss: 0.2920\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2990 - val_loss: 0.2932\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2940 - val_loss: 0.2857\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2926 - val_loss: 0.3148\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2938 - val_loss: 0.3570\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3112 - val_loss: 0.2876\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2991 - val_loss: 0.3106\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2931 - val_loss: 0.2915\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2881 - val_loss: 0.2879\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2852 - val_loss: 0.3139\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2797 - val_loss: 0.3076\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2823 - val_loss: 0.2900\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2972 - val_loss: 0.3418\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3057\n",
            "[CV]  n_neurons=30, n_hidden=3, learning_rate=0.0045455096956331, total=  41.2s\n",
            "[CV] n_neurons=49, n_hidden=1, learning_rate=0.0020587676114196545 ...\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 3.4800 - val_loss: 29.5063\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.8491 - val_loss: 33.7784\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.8416 - val_loss: 4.0125\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6237 - val_loss: 0.5556\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5755 - val_loss: 0.5119\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5306 - val_loss: 0.4888\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5198 - val_loss: 0.4729\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4973 - val_loss: 0.4559\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4747 - val_loss: 0.4601\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4664 - val_loss: 0.4303\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4450 - val_loss: 0.4205\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4195 - val_loss: 0.4242\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4480 - val_loss: 0.4107\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4328 - val_loss: 0.4231\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4293 - val_loss: 0.4221\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4155 - val_loss: 0.4084\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4334 - val_loss: 0.4209\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4284 - val_loss: 0.4017\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4067 - val_loss: 0.4322\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4111 - val_loss: 0.4001\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4041 - val_loss: 0.4263\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3951 - val_loss: 0.4032\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4104 - val_loss: 0.4039\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3942 - val_loss: 0.3764\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4024 - val_loss: 0.4241\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3863 - val_loss: 0.3779\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4067 - val_loss: 0.4126\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3956 - val_loss: 0.3967\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3976 - val_loss: 0.4045\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3876 - val_loss: 0.3748\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3863 - val_loss: 0.3717\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3676\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3779 - val_loss: 0.4054\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3758 - val_loss: 0.3924\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3782 - val_loss: 0.3611\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3750 - val_loss: 0.4182\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3769 - val_loss: 0.3539\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3741 - val_loss: 0.4403\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3729 - val_loss: 0.3551\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3570 - val_loss: 0.4125\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3686 - val_loss: 0.3665\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3748 - val_loss: 0.3591\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3709 - val_loss: 0.3570\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3702 - val_loss: 0.4125\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3743 - val_loss: 0.3547\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3585 - val_loss: 0.3779\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3692 - val_loss: 0.3886\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3877\n",
            "[CV]  n_neurons=49, n_hidden=1, learning_rate=0.0020587676114196545, total=  22.3s\n",
            "[CV] n_neurons=49, n_hidden=1, learning_rate=0.0020587676114196545 ...\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 3.3075 - val_loss: 0.7805\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7479 - val_loss: 1.1550\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6249 - val_loss: 1.8115\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5885 - val_loss: 2.6113\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5412 - val_loss: 3.2626\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5083 - val_loss: 3.5247\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4786 - val_loss: 3.5926\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4660 - val_loss: 3.5562\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4559 - val_loss: 2.9541\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4427 - val_loss: 2.5606\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4424 - val_loss: 2.1560\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.4866\n",
            "[CV]  n_neurons=49, n_hidden=1, learning_rate=0.0020587676114196545, total=   5.6s\n",
            "[CV] n_neurons=49, n_hidden=1, learning_rate=0.0020587676114196545 ...\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.9276 - val_loss: 2.5834\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.7344 - val_loss: 3.5564\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6461 - val_loss: 1.7895\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6260 - val_loss: 1.7436\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5519 - val_loss: 0.6344\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5085 - val_loss: 0.8713\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5055 - val_loss: 0.5604\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5012 - val_loss: 0.4695\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4772 - val_loss: 0.4942\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4582 - val_loss: 0.4375\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4637 - val_loss: 0.4536\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4395 - val_loss: 0.4276\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4150 - val_loss: 0.4084\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4219 - val_loss: 0.4897\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4455 - val_loss: 0.4018\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4279 - val_loss: 0.5505\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4079 - val_loss: 0.4602\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4250 - val_loss: 0.4347\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4231 - val_loss: 0.3835\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4083 - val_loss: 0.4115\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4025 - val_loss: 0.3817\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4214 - val_loss: 0.3737\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4011 - val_loss: 0.3720\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3929 - val_loss: 0.4318\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3957 - val_loss: 0.4158\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3918 - val_loss: 0.3821\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4040 - val_loss: 0.4069\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3972 - val_loss: 0.4024\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3859 - val_loss: 0.5904\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3872 - val_loss: 0.4027\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3742 - val_loss: 0.4216\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4065 - val_loss: 0.3603\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.4134\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3744 - val_loss: 0.3633\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3720 - val_loss: 0.3542\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3710 - val_loss: 0.3568\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.4216\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3764 - val_loss: 0.5522\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3867 - val_loss: 0.5648\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3818 - val_loss: 0.6416\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3684 - val_loss: 0.3847\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3616 - val_loss: 0.5255\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3771 - val_loss: 0.7023\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.7508\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3698 - val_loss: 0.5608\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3745\n",
            "[CV]  n_neurons=49, n_hidden=1, learning_rate=0.0020587676114196545, total=  22.1s\n",
            "[CV] n_neurons=74, n_hidden=3, learning_rate=0.005803602934201024 ....\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.6933 - val_loss: 6.4183\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.6124 - val_loss: 16.7917\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5548 - val_loss: 4.7823\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4575 - val_loss: 8.6077\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4166 - val_loss: 1.8032\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4075 - val_loss: 0.3654\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3664 - val_loss: 0.3783\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3529 - val_loss: 0.4054\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3455 - val_loss: 0.3908\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3490 - val_loss: 0.3907\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3308 - val_loss: 0.3551\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3169 - val_loss: 0.3610\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3465 - val_loss: 0.3666\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3317 - val_loss: 0.3634\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3252 - val_loss: 0.3566\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3238 - val_loss: 0.3551\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3329 - val_loss: 0.3585\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3389 - val_loss: 0.3477\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3133 - val_loss: 0.3538\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3204 - val_loss: 0.3402\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3156 - val_loss: 0.3368\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3061 - val_loss: 0.3521\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3150 - val_loss: 0.3344\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3087 - val_loss: 0.3083\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3106 - val_loss: 0.3490\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2952 - val_loss: 0.3068\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3113 - val_loss: 0.3315\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3057 - val_loss: 0.3432\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2991 - val_loss: 0.3287\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2990 - val_loss: 0.2965\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2952 - val_loss: 0.3084\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2851 - val_loss: 0.2892\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2897 - val_loss: 0.3232\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2832 - val_loss: 0.3195\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2852 - val_loss: 0.2899\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2863 - val_loss: 0.3649\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2761 - val_loss: 0.3278\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2935 - val_loss: 0.3629\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2785 - val_loss: 0.2915\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2661 - val_loss: 0.3406\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2759 - val_loss: 0.2891\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2773 - val_loss: 0.2998\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2782 - val_loss: 0.2834\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2744 - val_loss: 0.3227\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2793 - val_loss: 0.2889\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2658 - val_loss: 0.3256\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2678 - val_loss: 0.2914\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2654 - val_loss: 0.2875\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2783 - val_loss: 0.3046\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2662 - val_loss: 0.3588\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2593 - val_loss: 0.3173\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2764 - val_loss: 0.3153\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2636 - val_loss: 0.2823\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2578 - val_loss: 0.2857\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2570 - val_loss: 0.2935\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2753 - val_loss: 0.2835\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2697 - val_loss: 0.3031\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2625 - val_loss: 0.2830\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2679 - val_loss: 0.2777\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2560 - val_loss: 0.2831\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2543 - val_loss: 0.3228\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2571 - val_loss: 0.2898\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2616 - val_loss: 0.3042\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2517 - val_loss: 0.3132\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2454 - val_loss: 0.2758\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2665 - val_loss: 0.2946\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2585 - val_loss: 0.2743\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2559 - val_loss: 0.3590\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2546 - val_loss: 0.3055\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2679 - val_loss: 0.4051\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2597 - val_loss: 0.2856\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2670 - val_loss: 0.3739\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2607 - val_loss: 0.3000\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2641 - val_loss: 0.4421\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2514 - val_loss: 0.2881\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2616 - val_loss: 0.3807\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.2487 - val_loss: 0.3306\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3046\n",
            "[CV]  n_neurons=74, n_hidden=3, learning_rate=0.005803602934201024, total=  42.0s\n",
            "[CV] n_neurons=74, n_hidden=3, learning_rate=0.005803602934201024 ....\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.4417 - val_loss: 0.7369\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5298 - val_loss: 0.4431\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4286 - val_loss: 0.3919\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4017 - val_loss: 0.3834\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3837 - val_loss: 0.3951\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3655 - val_loss: 0.4649\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3497 - val_loss: 0.6402\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3530 - val_loss: 0.7264\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3417 - val_loss: 0.9112\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3458 - val_loss: 0.6988\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3395 - val_loss: 0.6965\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3254 - val_loss: 0.7818\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3186 - val_loss: 0.8583\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3123 - val_loss: 0.8268\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3523\n",
            "[CV]  n_neurons=74, n_hidden=3, learning_rate=0.005803602934201024, total=   8.6s\n",
            "[CV] n_neurons=74, n_hidden=3, learning_rate=0.005803602934201024 ....\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.6880 - val_loss: 0.9196\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4943 - val_loss: 2.1025\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4287 - val_loss: 3.5511\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4621 - val_loss: 1.5867\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3738 - val_loss: 0.4227\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3522 - val_loss: 0.3738\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3500 - val_loss: 0.3350\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3672 - val_loss: 0.3384\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3477 - val_loss: 0.3720\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3506 - val_loss: 0.3274\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3651 - val_loss: 0.3958\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3353 - val_loss: 0.3324\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3091 - val_loss: 0.3226\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3206 - val_loss: 0.3680\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3453 - val_loss: 0.3212\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3254 - val_loss: 0.3531\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3125 - val_loss: 0.3216\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 0.3226 - val_loss: 0.3551\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3344 - val_loss: 0.3391\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3248 - val_loss: 0.3703\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3150 - val_loss: 0.3188\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3265 - val_loss: 0.3348\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3111 - val_loss: 0.3798\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3033 - val_loss: 0.3030\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3006 - val_loss: 0.3138\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2996 - val_loss: 0.3231\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3137 - val_loss: 0.3172\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3101 - val_loss: 0.3496\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3095 - val_loss: 0.4200\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3025 - val_loss: 0.3075\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2894 - val_loss: 0.3259\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3080 - val_loss: 0.3018\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2982 - val_loss: 0.3395\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2854 - val_loss: 0.3008\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2831 - val_loss: 0.2933\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2783 - val_loss: 0.4254\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2903 - val_loss: 0.3565\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2957 - val_loss: 0.4229\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3005 - val_loss: 0.3167\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2855 - val_loss: 0.3501\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2693 - val_loss: 0.3195\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2793 - val_loss: 0.3239\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2926 - val_loss: 0.2829\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2922 - val_loss: 0.3362\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2739 - val_loss: 0.2948\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2755 - val_loss: 0.3316\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2774 - val_loss: 0.2827\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2727 - val_loss: 0.2924\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2797 - val_loss: 0.3845\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2799 - val_loss: 0.2996\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2822 - val_loss: 0.3465\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2686 - val_loss: 0.2966\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2788 - val_loss: 0.2925\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2742 - val_loss: 0.2985\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2669 - val_loss: 0.2842\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2777 - val_loss: 0.3031\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2725 - val_loss: 0.3385\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.2932\n",
            "[CV]  n_neurons=74, n_hidden=3, learning_rate=0.005803602934201024, total=  32.7s\n",
            "[CV] n_neurons=80, n_hidden=3, learning_rate=0.0059640580092043885 ...\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.5786 - val_loss: 10.9251\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5353 - val_loss: 3.3912\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4521 - val_loss: 0.4039\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4084 - val_loss: 0.3692\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3670 - val_loss: 0.3555\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3524 - val_loss: 0.3875\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3487 - val_loss: 0.3633\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3423 - val_loss: 0.3991\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3333 - val_loss: 0.3796\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3379 - val_loss: 0.3705\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3209 - val_loss: 0.3312\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3109 - val_loss: 0.3509\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3375 - val_loss: 0.3786\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3224 - val_loss: 0.3317\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3175 - val_loss: 0.3486\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3173 - val_loss: 0.3478\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3260 - val_loss: 0.3251\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3304 - val_loss: 0.3433\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3066 - val_loss: 0.3354\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3130 - val_loss: 0.3224\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3090 - val_loss: 0.3993\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3034 - val_loss: 0.3111\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3066 - val_loss: 0.3661\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3035 - val_loss: 0.3607\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3095 - val_loss: 0.3817\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2910 - val_loss: 0.3184\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3104 - val_loss: 0.3437\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3000 - val_loss: 0.3337\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2931 - val_loss: 0.3427\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2949 - val_loss: 0.3457\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2957 - val_loss: 0.3316\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2828 - val_loss: 0.2905\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2860 - val_loss: 0.3327\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2812 - val_loss: 0.3000\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2807 - val_loss: 0.2955\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2827 - val_loss: 0.3640\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2734 - val_loss: 0.4132\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2966 - val_loss: 0.3667\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2798 - val_loss: 0.2883\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2644 - val_loss: 0.3277\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2765 - val_loss: 0.2890\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2758 - val_loss: 0.3074\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2775 - val_loss: 0.2817\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2720 - val_loss: 0.3168\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2759 - val_loss: 0.2792\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2633 - val_loss: 0.3145\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2672 - val_loss: 0.3142\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2626 - val_loss: 0.3069\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2790 - val_loss: 0.2778\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2653 - val_loss: 0.3284\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2553 - val_loss: 0.3356\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2739 - val_loss: 0.3182\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2599 - val_loss: 0.2938\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2538 - val_loss: 0.2900\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2580 - val_loss: 0.3171\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2779 - val_loss: 0.2839\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2676 - val_loss: 0.3232\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2645 - val_loss: 0.3031\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2696 - val_loss: 0.2865\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3031\n",
            "[CV]  n_neurons=80, n_hidden=3, learning_rate=0.0059640580092043885, total=  33.2s\n",
            "[CV] n_neurons=80, n_hidden=3, learning_rate=0.0059640580092043885 ...\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.5488 - val_loss: 0.6551\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4745 - val_loss: 0.4129\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4052 - val_loss: 0.6096\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3959 - val_loss: 0.6534\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3826 - val_loss: 0.6227\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3631 - val_loss: 0.8403\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3493 - val_loss: 1.0599\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3562 - val_loss: 1.1357\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3392 - val_loss: 1.2306\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3463 - val_loss: 0.8012\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3414 - val_loss: 0.8288\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3264 - val_loss: 0.7647\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3590\n",
            "[CV]  n_neurons=80, n_hidden=3, learning_rate=0.0059640580092043885, total=   7.3s\n",
            "[CV] n_neurons=80, n_hidden=3, learning_rate=0.0059640580092043885 ...\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 1.4295 - val_loss: 2.2007\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5148 - val_loss: 3.3028\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4423 - val_loss: 0.9130\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4027 - val_loss: 0.5328\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3757 - val_loss: 0.3609\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3528 - val_loss: 0.4151\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3518 - val_loss: 0.3580\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3723 - val_loss: 0.3516\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3488 - val_loss: 0.3983\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3449 - val_loss: 0.3323\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3567 - val_loss: 0.4233\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3353 - val_loss: 0.3284\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3110 - val_loss: 0.3469\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3199 - val_loss: 0.4037\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3410 - val_loss: 0.3270\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3264 - val_loss: 0.3781\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3131 - val_loss: 0.3214\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3198 - val_loss: 0.3292\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3350 - val_loss: 0.3859\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3248 - val_loss: 0.3273\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3157 - val_loss: 0.3902\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3275 - val_loss: 0.3128\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3094 - val_loss: 0.3452\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3031 - val_loss: 0.3199\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3003 - val_loss: 0.3082\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3015 - val_loss: 0.3068\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3127 - val_loss: 0.4238\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3127 - val_loss: 0.3474\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3014 - val_loss: 0.3654\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2999 - val_loss: 0.3370\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2882 - val_loss: 0.3176\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3077 - val_loss: 0.4380\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2986 - val_loss: 0.2989\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2848 - val_loss: 0.3658\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2900 - val_loss: 0.3071\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2806 - val_loss: 0.3975\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2903 - val_loss: 0.3058\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2889 - val_loss: 0.4518\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3008 - val_loss: 0.2963\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2855 - val_loss: 0.3591\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2709 - val_loss: 0.3166\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2763 - val_loss: 0.4088\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2893 - val_loss: 0.3100\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2936 - val_loss: 0.3493\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2771 - val_loss: 0.3008\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2755 - val_loss: 0.3766\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2768 - val_loss: 0.2858\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2713 - val_loss: 0.2839\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2802 - val_loss: 0.4853\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2780 - val_loss: 0.3313\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2825 - val_loss: 0.5703\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2662 - val_loss: 0.4747\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2761 - val_loss: 0.3474\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2753 - val_loss: 0.3624\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2699 - val_loss: 0.3036\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2745 - val_loss: 0.3680\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2696 - val_loss: 0.3009\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2790 - val_loss: 0.3382\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.2892\n",
            "[CV]  n_neurons=80, n_hidden=3, learning_rate=0.0059640580092043885, total=  32.8s\n",
            "[CV] n_neurons=59, n_hidden=2, learning_rate=0.004591455636549438 ....\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 2.1527 - val_loss: 0.5753\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5713 - val_loss: 8.9878\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5292 - val_loss: 11.0986\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5126 - val_loss: 1.1306\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4298 - val_loss: 0.5256\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3984 - val_loss: 0.4498\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3937 - val_loss: 0.4056\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3816 - val_loss: 0.3999\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3687 - val_loss: 0.3957\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3701 - val_loss: 0.3904\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3540 - val_loss: 0.3688\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3395 - val_loss: 0.3651\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3672 - val_loss: 0.3709\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3528 - val_loss: 0.3816\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3518 - val_loss: 0.3620\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3489 - val_loss: 0.3670\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3555 - val_loss: 0.3671\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3620 - val_loss: 0.3605\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3404 - val_loss: 0.3552\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3444 - val_loss: 0.3538\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3381 - val_loss: 0.3520\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3314 - val_loss: 0.3477\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3413 - val_loss: 0.3509\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3381 - val_loss: 0.3304\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3398 - val_loss: 0.3686\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3262 - val_loss: 0.3246\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3448 - val_loss: 0.3389\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3375 - val_loss: 0.3368\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3318 - val_loss: 0.3388\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3303 - val_loss: 0.3212\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3299 - val_loss: 0.3220\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3206 - val_loss: 0.3150\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3229 - val_loss: 0.3453\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3196 - val_loss: 0.3164\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3166 - val_loss: 0.3140\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3178 - val_loss: 0.3899\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3101 - val_loss: 0.3812\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3263 - val_loss: 0.3407\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3117 - val_loss: 0.3149\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3008 - val_loss: 0.3379\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3139 - val_loss: 0.3147\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3161 - val_loss: 0.3145\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3167 - val_loss: 0.3102\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3092 - val_loss: 0.3409\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3167 - val_loss: 0.3051\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3002 - val_loss: 0.3336\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3051 - val_loss: 0.3330\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2948 - val_loss: 0.3182\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3177 - val_loss: 0.3019\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3038 - val_loss: 0.3632\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2902 - val_loss: 0.3293\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3165 - val_loss: 0.3480\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2996 - val_loss: 0.3076\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2970 - val_loss: 0.3099\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2969 - val_loss: 0.3426\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3191 - val_loss: 0.2995\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3056 - val_loss: 0.3785\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3018 - val_loss: 0.3196\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3064 - val_loss: 0.2980\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3000 - val_loss: 0.3287\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2891 - val_loss: 0.3284\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2928 - val_loss: 0.3563\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3018 - val_loss: 0.3106\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2895 - val_loss: 0.3939\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2813 - val_loss: 0.2956\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3099 - val_loss: 0.3258\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2978 - val_loss: 0.3411\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2931 - val_loss: 0.3065\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2925 - val_loss: 0.3694\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3147 - val_loss: 0.2944\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2934 - val_loss: 0.3929\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3090 - val_loss: 0.3015\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3005 - val_loss: 0.2958\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2996 - val_loss: 0.4257\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2869 - val_loss: 0.2971\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2929 - val_loss: 0.3889\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2829 - val_loss: 0.5728\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.2896 - val_loss: 0.7754\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3014 - val_loss: 0.3581\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.2843 - val_loss: 0.4556\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3230\n",
            "[CV]  n_neurons=59, n_hidden=2, learning_rate=0.004591455636549438, total=  42.1s\n",
            "[CV] n_neurons=59, n_hidden=2, learning_rate=0.004591455636549438 ....\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 2.2993 - val_loss: 0.8898\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.5586 - val_loss: 0.5270\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4526 - val_loss: 0.4844\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4289 - val_loss: 0.4250\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4117 - val_loss: 0.3735\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3892 - val_loss: 0.3859\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3723 - val_loss: 0.4576\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3751 - val_loss: 0.4926\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3636 - val_loss: 0.6246\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3692 - val_loss: 0.5262\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3671 - val_loss: 0.5952\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3472 - val_loss: 0.6355\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3456 - val_loss: 0.7437\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3353 - val_loss: 0.7098\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3649 - val_loss: 0.6818\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3613\n",
            "[CV]  n_neurons=59, n_hidden=2, learning_rate=0.004591455636549438, total=   8.6s\n",
            "[CV] n_neurons=59, n_hidden=2, learning_rate=0.004591455636549438 ....\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 3ms/step - loss: 2.1229 - val_loss: 2.8528\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.6059 - val_loss: 2.3412\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.5163 - val_loss: 0.9015\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4576 - val_loss: 0.8313\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.4213 - val_loss: 0.5217\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3916 - val_loss: 0.4956\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3878 - val_loss: 0.3745\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.4044 - val_loss: 0.4012\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3805 - val_loss: 0.4169\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3769 - val_loss: 0.3843\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3900 - val_loss: 0.6126\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3622 - val_loss: 0.3577\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3398 - val_loss: 0.3496\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3487 - val_loss: 0.5422\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3736 - val_loss: 0.4645\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3588 - val_loss: 0.6065\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3435 - val_loss: 0.4792\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3556 - val_loss: 0.4718\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3685 - val_loss: 0.3399\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3535 - val_loss: 0.3999\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3452 - val_loss: 0.3297\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3579 - val_loss: 0.3296\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3393 - val_loss: 0.3287\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3354 - val_loss: 0.5189\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3320 - val_loss: 0.8180\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3356 - val_loss: 0.9098\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3824 - val_loss: 0.5094\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3448 - val_loss: 0.6113\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3345 - val_loss: 0.3338\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3345 - val_loss: 0.5126\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 2ms/step - loss: 0.3223 - val_loss: 0.3448\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3444 - val_loss: 0.6960\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 0s 2ms/step - loss: 0.3353 - val_loss: 0.3845\n",
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3362\n",
            "[CV]  n_neurons=59, n_hidden=2, learning_rate=0.004591455636549438, total=  17.5s\n",
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  9.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "363/363 [==============================] - 1s 2ms/step - loss: 1.4030 - val_loss: 1.8036\n",
            "Epoch 2/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5715 - val_loss: 2.0827\n",
            "Epoch 3/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4548 - val_loss: 0.3796\n",
            "Epoch 4/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4007 - val_loss: 0.4283\n",
            "Epoch 5/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3832 - val_loss: 0.3617\n",
            "Epoch 6/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3677 - val_loss: 0.4566\n",
            "Epoch 7/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3732 - val_loss: 0.3573\n",
            "Epoch 8/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3580 - val_loss: 0.3380\n",
            "Epoch 9/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3458 - val_loss: 0.3757\n",
            "Epoch 10/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3433 - val_loss: 0.4069\n",
            "Epoch 11/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3312 - val_loss: 0.5457\n",
            "Epoch 12/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3456 - val_loss: 0.6471\n",
            "Epoch 13/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3320 - val_loss: 0.3109\n",
            "Epoch 14/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3259 - val_loss: 0.3205\n",
            "Epoch 15/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3223 - val_loss: 0.3063\n",
            "Epoch 16/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3276 - val_loss: 0.3251\n",
            "Epoch 17/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3095 - val_loss: 0.4025\n",
            "Epoch 18/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3108 - val_loss: 0.2990\n",
            "Epoch 19/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3060 - val_loss: 0.3052\n",
            "Epoch 20/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3003 - val_loss: 0.4798\n",
            "Epoch 21/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3097 - val_loss: 0.3388\n",
            "Epoch 22/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2953 - val_loss: 0.5051\n",
            "Epoch 23/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3125 - val_loss: 0.5649\n",
            "Epoch 24/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3035 - val_loss: 0.5182\n",
            "Epoch 25/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2991 - val_loss: 0.3266\n",
            "Epoch 26/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.2991 - val_loss: 0.4939\n",
            "Epoch 27/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3002 - val_loss: 0.5481\n",
            "Epoch 28/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3049 - val_loss: 0.4383\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fb06ed97210>,\n",
              "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
              "                   param_distributions={'learning_rate': [0.001683454924600351,\n",
              "                                                          0.02390836445593178,\n",
              "                                                          0.008731907739399206,\n",
              "                                                          0.004725396149933917,\n",
              "                                                          0.0006154014789262348,\n",
              "                                                          0.0006153331256530192,\n",
              "                                                          0.000392002...\n",
              "                                                          0.0024505367684280487,\n",
              "                                                          0.011155092541719619,\n",
              "                                                          0.0007524347058135697,\n",
              "                                                          0.0032032448128444043,\n",
              "                                                          0.004591455636549438,\n",
              "                                                          0.0003715541189658278, ...],\n",
              "                                        'n_hidden': [0, 1, 2, 3],\n",
              "                                        'n_neurons': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
              "                                                      10, 11, 12, 13, 14, 15,\n",
              "                                                      16, 17, 18, 19, 20, 21,\n",
              "                                                      22, 23, 24, 25, 26, 27,\n",
              "                                                      28, 29, 30, ...]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTBhuXAqN8Gk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cf710fc-46e5-4907-8673-3258a20f4cb7"
      },
      "source": [
        "rnd_search_cv.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.005803602934201024, 'n_hidden': 3, 'n_neurons': 74}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3wWcRxpN8Gk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c18f7ed-2f75-4633-c984-6b2289025f34"
      },
      "source": [
        "rnd_search_cv.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.316694974899292"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYfBbWYvN8Gk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34096240-5853-4222-bcd9-9d3f29a4fdf8"
      },
      "source": [
        "rnd_search_cv.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor at 0x7fb075a174d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iONJ2XUNN8Gk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc2f3822-200a-4139-aac3-f7459feea839"
      },
      "source": [
        "rnd_search_cv.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "162/162 [==============================] - 0s 919us/step - loss: 0.3026\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.3025602102279663"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nDXZilKN8Gl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45fbeaa6-4974-4465-d62e-3b0874fed9b0"
      },
      "source": [
        "model = rnd_search_cv.best_estimator_.model\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.sequential.Sequential at 0x7fb075812990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "aRjNSs6cN8Gl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89c1bb16-dab7-42db-a158-45520afa7c2b"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "162/162 [==============================] - 0s 936us/step - loss: 0.3026\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3025602102279663"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrVbzUDfN8Gl"
      },
      "source": [
        "# Exercise solutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYjqWNIWN8Gl"
      },
      "source": [
        "## 1. to 9."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aNI9_bkN8Gl"
      },
      "source": [
        "See appendix A."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oc0OVnxbN8Gl"
      },
      "source": [
        "## 10."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05kC9QQJN8Gm"
      },
      "source": [
        "*Exercise: Train a deep MLP on the MNIST dataset (you can load it using `keras.datasets.mnist.load_data()`. See if you can get over 98% precision. Try searching for the optimal learning rate by using the approach presented in this chapter (i.e., by growing the learning rate exponentially, plotting the loss, and finding the point where the loss shoots up). Try adding all the bells and whistles—save checkpoints, use early stopping, and plot learning curves using TensorBoard.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQqBDa6cN8Gm"
      },
      "source": [
        "Let's load the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCSCsacXN8Gm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e685f3f-be03-45fb-869d-c541b43d5c94"
      },
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLxMB50uN8Gm"
      },
      "source": [
        "Just like for the Fashion MNIST dataset, the MNIST training set contains 60,000 grayscale images, each 28x28 pixels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhVAPkhDN8Gm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fcf6e79-ed4e-4d00-fa2f-201d7d9aca3b"
      },
      "source": [
        "X_train_full.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO2ZgtPIN8Gn"
      },
      "source": [
        "Each pixel intensity is also represented as a byte (0 to 255):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESBrVzC3N8Gn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7497ad64-3a27-406e-af06-0e8db0fcfe17"
      },
      "source": [
        "X_train_full.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkXmxXVoN8Gn"
      },
      "source": [
        "Let's split the full training set into a validation set and a (smaller) training set. We also scale the pixel intensities down to the 0-1 range and convert them to floats, by dividing by 255, just like we did for Fashion MNIST:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QntpKcvN8Gn"
      },
      "source": [
        "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "X_test = X_test / 255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMgMqqNeN8Gn"
      },
      "source": [
        "Let's plot an image using Matplotlib's `imshow()` function, with a `'binary'`\n",
        " color map:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNE34Q_zN8Gn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e0b764a-622a-40cc-debf-130eb9b0fdd5"
      },
      "source": [
        "plt.imshow(X_train[0], cmap=\"binary\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mt1ByxXeN8Go"
      },
      "source": [
        "The labels are the class IDs (represented as uint8), from 0 to 9. Conveniently, the class IDs correspond to the digits represented in the images, so we don't need a `class_names` array:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sXauBb2N8Go",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c696fda-974c-454c-a151-cf04711a1740"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 3, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEW-NFPLN8Go"
      },
      "source": [
        "The validation set contains 5,000 images, and the test set contains 10,000 images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SEDs0-MN8Go",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a34a24b-d571-419a-e106-9614804e883c"
      },
      "source": [
        "X_valid.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anLv54zZN8Go",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eed3374a-5f25-41cf-a42c-087fb9e902a3"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Xm5xEArN8Gp"
      },
      "source": [
        "Let's take a look at a sample of the images in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHYfoSYzN8Gp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e320142-7f4b-4bfa-bd95-8665298f9172"
      },
      "source": [
        "n_rows = 4\n",
        "n_cols = 10\n",
        "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
        "for row in range(n_rows):\n",
        "    for col in range(n_cols):\n",
        "        index = n_cols * row + col\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
        "        plt.axis('off')\n",
        "        plt.title(y_train[index], fontsize=12)\n",
        "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x345.6 with 40 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmPLAAmfN8Gp"
      },
      "source": [
        "Let's build a simple dense network and find the optimal learning rate. We will need a callback to grow the learning rate at each iteration. It will also record the learning rate and the loss at each iteration:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e245pajAN8Gp"
      },
      "source": [
        "K = keras.backend\n",
        "\n",
        "class ExponentialLearningRate(keras.callbacks.Callback):\n",
        "    def __init__(self, factor):\n",
        "        self.factor = factor\n",
        "        self.rates = []\n",
        "        self.losses = []\n",
        "    def on_batch_end(self, batch, logs):\n",
        "        self.rates.append(K.get_value(self.model.optimizer.lr))\n",
        "        self.losses.append(logs[\"loss\"])\n",
        "        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87ejCq6fN8Gp"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hteI_H6iN8Gq"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSd16IMQN8Gq"
      },
      "source": [
        "We will start with a small learning rate of 1e-3, and grow it by 0.5% at each iteration:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wnxp3JpHN8Gq"
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
        "              metrics=[\"accuracy\"])\n",
        "expon_lr = ExponentialLearningRate(factor=1.005)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZHmAlcXN8Gq"
      },
      "source": [
        "Now let's train the model for just 1 epoch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1nVVNM2N8Gq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "852ec098-5ee6-4c48-f903-e89eff549994"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=1,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[expon_lr])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1719/1719 [==============================] - 8s 4ms/step - loss: 7264674801477675384832.0000 - accuracy: 0.4891 - val_loss: 2.3911 - val_accuracy: 0.1126\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRwxklesN8Gr"
      },
      "source": [
        "We can now plot the loss as a functionof the learning rate:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiJI5quYN8Gr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a26a2dba-e9e6-4165-d2ca-9e72363dbcc1"
      },
      "source": [
        "plt.plot(expon_lr.rates, expon_lr.losses)\n",
        "plt.gca().set_xscale('log')\n",
        "plt.hlines(min(expon_lr.losses), min(expon_lr.rates), max(expon_lr.rates))\n",
        "plt.axis([min(expon_lr.rates), max(expon_lr.rates), 0, expon_lr.losses[0]])\n",
        "plt.grid()\n",
        "plt.xlabel(\"Learning rate\")\n",
        "plt.ylabel(\"Loss\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQTRLO5wN8Gr"
      },
      "source": [
        "The loss starts shooting back up violently when the learning rate goes over 6e-1, so let's try using half of that, at 3e-1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1NDv_ZiN8Gr"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72H60jrbN8Gr"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks14ZJltN8Gr"
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(lr=3e-1),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3eOtV2FN8Gs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9770cd50-7b7e-4aaf-c657-aab17ed12335"
      },
      "source": [
        "run_index = 1 # increment this at every run\n",
        "run_logdir = os.path.join(os.curdir, \"my_mnist_logs\", \"run_{:03d}\".format(run_index))\n",
        "run_logdir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./my_mnist_logs/run_001'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh_ULaQ1N8Gs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f81c477-f65c-4fbf-af74-247c02f62d56"
      },
      "source": [
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_mnist_model.h5\", save_best_only=True)\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=100,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4201 - accuracy: 0.8674 - val_loss: 0.1048 - val_accuracy: 0.9682\n",
            "Epoch 2/100\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0933 - accuracy: 0.9705 - val_loss: 0.0972 - val_accuracy: 0.9716\n",
            "Epoch 3/100\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0685 - accuracy: 0.9778 - val_loss: 0.0703 - val_accuracy: 0.9788\n",
            "Epoch 4/100\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0455 - accuracy: 0.9854 - val_loss: 0.0766 - val_accuracy: 0.9792\n",
            "Epoch 5/100\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0330 - accuracy: 0.9897 - val_loss: 0.0839 - val_accuracy: 0.9760\n",
            "Epoch 6/100\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0299 - accuracy: 0.9908 - val_loss: 0.0758 - val_accuracy: 0.9800\n",
            "Epoch 7/100\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0256 - accuracy: 0.9910 - val_loss: 0.0951 - val_accuracy: 0.9782\n",
            "Epoch 8/100\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.0946 - val_accuracy: 0.9774\n",
            "Epoch 9/100\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0176 - accuracy: 0.9941 - val_loss: 0.0879 - val_accuracy: 0.9810\n",
            "Epoch 10/100\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.0794 - val_accuracy: 0.9828\n",
            "Epoch 11/100\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0821 - val_accuracy: 0.9832\n",
            "Epoch 12/100\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0971 - val_accuracy: 0.9816\n",
            "Epoch 13/100\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.0982 - val_accuracy: 0.9754\n",
            "Epoch 14/100\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.0863 - val_accuracy: 0.9842\n",
            "Epoch 15/100\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.1016 - val_accuracy: 0.9816\n",
            "Epoch 16/100\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0935 - val_accuracy: 0.9846\n",
            "Epoch 17/100\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.1002 - val_accuracy: 0.9834\n",
            "Epoch 18/100\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.0942 - val_accuracy: 0.9828\n",
            "Epoch 19/100\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.0933 - val_accuracy: 0.9838\n",
            "Epoch 20/100\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0939 - val_accuracy: 0.9832\n",
            "Epoch 21/100\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.0915 - val_accuracy: 0.9840\n",
            "Epoch 22/100\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.1228 - val_accuracy: 0.9810\n",
            "Epoch 23/100\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.1077 - val_accuracy: 0.9828\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7CyOgbKN8Gs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "915ce0c6-fdd2-464d-a849-9a522962df1b"
      },
      "source": [
        "model = keras.models.load_model(\"my_mnist_model.h5\") # rollback to best model\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0799 - accuracy: 0.9753\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07990259677171707, 0.9753000140190125]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hAIwCpJN8Gs"
      },
      "source": [
        "We got over 98% accuracy. Finally, let's look at the learning curves using TensorBoard:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZQ9PA9wN8Gt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df729087-171b-402b-a900-51b5a3b614f2"
      },
      "source": [
        "%tensorboard --logdir=./my_mnist_logs --port=6006"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ERROR: Failed to launch TensorBoard (exited with 255).\n",
              "Contents of stderr:\n",
              "2021-05-02 11:09:07.496309: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
              "E0502 11:09:09.954904 140063020865408 program.py:311] TensorBoard could not bind to port 6006, it was already in use\n",
              "ERROR: TensorBoard could not bind to port 6006, it was already in use"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-bk2NnlN8Gt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}